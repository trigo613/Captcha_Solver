{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3473a7a-4a6c-4b85-9de4-b087362c110e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "from numba import njit\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539e9d3-24f8-482d-9790-228d99f63bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4be62-0ac4-450b-904a-4da6baaf06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory where the dataset will be downloaded\n",
    "train_csv_path = 'D://ENGLISH_CHARACTERS//train_info.csv'\n",
    "test_csv_path = 'D://ENGLISH_CHARACTERS//test_info.csv'\n",
    "train_images_folder = 'D://ENGLISH_CHARACTERS//train'\n",
    "test_images_folder = 'D://ENGLISH_CHARACTERS//test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b73856-5cc0-404e-af3c-0337472f24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_train_df = pd.read_csv('D://EMNIST//emnist-digits-train.csv', header=None,dtype=np.uint8).sample(30_000)\n",
    "digits_test_df = pd.read_csv('D://EMNIST//emnist-digits-test.csv', header=None,dtype=np.uint8).sample(5_000)\n",
    "letters_train_df = pd.read_csv('D://EMNIST//emnist-letters-train.csv', header=None,dtype=np.uint8).sample(30_000)\n",
    "letters_train_df[0] += 9\n",
    "letters_test_df = pd.read_csv('D://EMNIST//emnist-letters-test.csv', header=None,dtype=np.uint8).sample(5_000)\n",
    "letters_test_df[0] += 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740254db-4283-4ce0-a5fc-03255ec52cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the character to number dictionary\n",
    "char_to_num = {\n",
    "    '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,\n",
    "    'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18,\n",
    "    'J': 19, 'K': 20, 'L': 21, 'M': 22, 'N': 23, 'O': 24, 'P': 25, 'Q': 26, 'R': 27,\n",
    "    'S': 28, 'T': 29, 'U': 30, 'V': 31, 'W': 32, 'X': 33, 'Y': 34, 'Z': 35\n",
    "}\n",
    "\n",
    "# Create the number to character dictionary by inverting char_to_num\n",
    "num_to_char = {v: k for k, v in char_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb2183-a9b7-4b85-a6db-1013e78c22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 36\n",
    "INPUT_SHAPE = (1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca044e-da18-463b-973c-34ccc5c4ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train DataFrames\n",
    "train_df = pd.concat([digits_train_df, letters_train_df,extra_train_df], axis=0, ignore_index=True)\n",
    "# Concatenate test DataFrames\n",
    "test_df = pd.concat([digits_test_df, letters_test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05527ff-4de9-4eb2-8d39-ab0fdd965645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process training data\n",
    "x_train = train_df.iloc[:, 1:].to_numpy().astype('float32')\n",
    "x_train = ((x_train.T - x_train.mean(axis=1)) / x_train.std(axis=1)).T\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28, 28).transpose(0, 1, 3, 2)\n",
    "y_train = train_df.iloc[:, 0].to_numpy().astype('uint8')\n",
    "\n",
    "# Process test data\n",
    "x_test = test_df.iloc[:, 1:].to_numpy().astype('float32')\n",
    "x_test = ((x_test.T - x_test.mean(axis=1)) / x_test.std(axis=1)).T\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28).transpose(0, 1, 3, 2)\n",
    "y_test = test_df.iloc[:, 0].to_numpy().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13805be9-e07e-4c45-b4a1-f8b51bbbe1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def scale_matrix(matrix):\n",
    "    min_val = np.min(matrix)\n",
    "    max_val = np.max(matrix)\n",
    "\n",
    "    if max_val - min_val == 0:\n",
    "        return np.zeros_like(matrix)\n",
    "\n",
    "    scaled_matrix = (matrix - min_val) / (max_val - min_val)\n",
    "    return scaled_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda1fdc-b73a-4493-8e15-731865054578",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = scale_matrix(x_train[i])\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i] = scale_matrix(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfd1e8-5e82-44c2-b1c3-863f259b68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def random_switch_pixels(matrix,p=0.02):\n",
    "    total_pixels = matrix.size\n",
    "    num_pixels_to_change = int(p * total_pixels)\n",
    "    indices_to_change = np.random.choice(total_pixels, num_pixels_to_change, replace=False)\n",
    "    flat_matrix = matrix.flatten()\n",
    "    flat_matrix[indices_to_change] = np.random.rand(num_pixels_to_change)\n",
    "    return flat_matrix.reshape(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8251c-f377-4568-ac4b-a1c2f78e158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def one_hot_encode_array(indices, num_classes=36):\n",
    "    n = len(indices)\n",
    "    one_hot_matrix = np.zeros((num_classes, n), dtype=np.int32)\n",
    "    for i in range(n):\n",
    "        one_hot_matrix[indices[i], i] = 1\n",
    "    return one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27f6ea-e621-408f-9438-862ce84b82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def one_hot_decode(one_hot_vector):\n",
    "    index = np.argmax(one_hot_vector)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff211b-a700-46a4-86a9-588276ed2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate_image(matrix, max_degrees):\n",
    "    # Ensure the input matrix has the correct shape (1,n,n)\n",
    "    if len(matrix.shape) != 3 or matrix.shape[0] != 1:\n",
    "        raise ValueError(\"Input matrix must have shape (1,n,n)\")\n",
    "    \n",
    "    # Generate a random angle in radians\n",
    "    angle = np.random.uniform(-max_degrees, max_degrees) * np.pi / 180\n",
    "    \n",
    "    # Create rotation matrix\n",
    "    n = matrix.shape[1]\n",
    "    cos_theta = np.cos(angle)\n",
    "    sin_theta = np.sin(angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_theta, -sin_theta],\n",
    "        [sin_theta, cos_theta]\n",
    "    ])\n",
    "    \n",
    "    # Apply rotation to each point\n",
    "    rotated_matrix = np.zeros_like(matrix)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            x, y = j - (n-1)/2, (n-1)/2 - i  # Translate to origin\n",
    "            x_rot, y_rot = np.dot(rotation_matrix, [x, y])\n",
    "            j_rot, i_rot = x_rot + (n-1)/2, (n-1)/2 - y_rot\n",
    "            \n",
    "            # Use bilinear interpolation for smoother results\n",
    "            i_low, j_low = int(np.floor(i_rot)), int(np.floor(j_rot))\n",
    "            i_high, j_high = i_low + 1, j_low + 1\n",
    "            \n",
    "            if 0 <= i_low < n-1 and 0 <= j_low < n-1:\n",
    "                tl = matrix[0, i_low, j_low]\n",
    "                tr = matrix[0, i_low, j_high]\n",
    "                bl = matrix[0, i_high, j_low]\n",
    "                br = matrix[0, i_high, j_high]\n",
    "                \n",
    "                wi = i_rot - i_low\n",
    "                wj = j_rot - j_low\n",
    "                \n",
    "                rotated_matrix[0, i, j] = (\n",
    "                    (1-wi)*(1-wj)*tl + wi*(1-wj)*bl + \n",
    "                    (1-wi)*wj*tr + wi*wj*br\n",
    "                )\n",
    "    \n",
    "    return rotated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7497dd-915e-4420-b940-d95bf64472a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_gray(value,gray_shades): \n",
    "    distances = np.abs(gray_shades - value)\n",
    "    min_id = np.argmin(distances)\n",
    "    return gray_shades[min_id]\n",
    "\n",
    "\n",
    "def clamp_grayscale_image(arr,gray_shades):\n",
    "    h, w = arr.shape\n",
    "    simplified_arr = np.zeros((h, w), dtype=np.float32)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            closest_shade = get_closest_gray(arr[i, j],gray_shades)\n",
    "            simplified_arr[i, j] = closest_shade\n",
    "    return simplified_arr\n",
    "\n",
    "def simplify_grayscale_image(matrix, num_levels=4, remove_outlier_percentage = 0.1, unique = False):\n",
    "    # Flatten the matrix to find min and max of the specified percentiles\n",
    "    flattened = matrix.flatten()\n",
    "    sorted_values = np.sort(flattened)\n",
    "    if remove_outlier_percentage > 0:\n",
    "        min_index = int(len(sorted_values) * remove_outlier_percentage)\n",
    "        max_index = int(len(sorted_values) * (1-remove_outlier_percentage))\n",
    "        sorted_values = sorted_values[min_index:max_index]\n",
    "    if unique:\n",
    "        sorted_values = np.unique(sorted_values)\n",
    "    # this is done for certain images that have outlier pixels and that is annoying for the algorithm\n",
    "    min_val = sorted_values[0]\n",
    "    max_val = sorted_values[-1]\n",
    "    gray_indices = np.linspace(0,len(sorted_values)-1,num_levels,dtype=int)\n",
    "    grays = sorted_values[gray_indices]\n",
    "    return clamp_grayscale_image(matrix,grays)\n",
    "\n",
    "def keep_highest(matrix):\n",
    "    simplified = matrix * (matrix == np.max(matrix))\n",
    "    return scale_matrix(simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84e442-1715-45b9-a41d-1cfa8a7b8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def random_shift_matrix(matrix, max_pixels):\n",
    "    # Ensure the input matrix has the correct shape (1,n,n)\n",
    "    if len(matrix.shape) != 3 or matrix.shape[0] != 1:\n",
    "        raise ValueError(\"Input matrix must have shape (1,n,n)\")\n",
    "    \n",
    "    # Generate random shifts for x and y\n",
    "    dx = np.random.randint(-max_pixels, max_pixels + 1)\n",
    "    dy = np.random.randint(-max_pixels, max_pixels + 1)\n",
    "    \n",
    "    n = matrix.shape[1]\n",
    "    shifted_matrix = np.zeros_like(matrix)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            new_i = i + dy\n",
    "            new_j = j + dx\n",
    "            \n",
    "            if 0 <= new_i < n and 0 <= new_j < n:\n",
    "                shifted_matrix[0, i, j] = matrix[0, new_i, new_j]\n",
    "            else:\n",
    "                # Optional: fill out-of-bounds pixels with a default value (e.g., 0)\n",
    "                shifted_matrix[0, i, j] = 0\n",
    "    \n",
    "    return shifted_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd6564-54f3-434c-b6a0-1cf3753296e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort_image(image):\n",
    "    out = image.copy()\n",
    "    out = random_switch_pixels(out,0.05)\n",
    "    out = random_rotate_image(out,45)\n",
    "    out = scale_matrix(out)\n",
    "    out = random_shift_matrix(out,3)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14b206-0bfd-4972-914e-1be69a4116a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes=36):  \n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Placeholder for fc_input_size\n",
    "        self.fc_input_size = None\n",
    "        \n",
    "        # Placeholder for fc layer\n",
    "        self.fc = None\n",
    "        \n",
    "        # Call method to initialize fc layer\n",
    "        self._initialize_fc(n_classes)\n",
    "\n",
    "    def _initialize_fc(self, n_classes):\n",
    "        sample_input = torch.zeros(1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(sample_input))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "        self.fc_input_size = x.shape[1]\n",
    "        self.fc = nn.Linear(self.fc_input_size, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f105be-ffd3-49e9-84a7-7ab51a864517",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "#model.load_state_dict(torch.load('./EMNIST_MODEL.pth',weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8118cb-d7a2-4dc5-95bb-1e043d72c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d052085a-ef4c-4de0-843e-cfa9e47bb3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    batch_size = 128\n",
    "    loops = len(x_train)//batch_size\n",
    "    indexes = list(range(len(x_train)))\n",
    "    print_every = loops//200\n",
    "    print('running for ', loops, ' rounds')\n",
    "    for i in range(loops):\n",
    "        ids = np.random.choice(indexes,size = batch_size)\n",
    "        indexes = [i for i in indexes if i not in ids]\n",
    "        inputs, labels = x_train[ids],y_train[ids]\n",
    "        inputs = np.array([distort_image(im) if np.random.ranf() < 0.4 else im for im in inputs])\n",
    "        labels = one_hot_encode_array(labels).transpose()\n",
    "        inputs = torch.Tensor(inputs).to(device)\n",
    "        labels = torch.Tensor(labels).to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % (print_every) == 0:    # print every 2000 mini-batches\n",
    "            torch.save(model.state_dict(), './EMNIST_MODEL.pth')\n",
    "            print(f'epoch : {epoch + 1}, mini_batch : [{i+1}/{loops}] ,  loss: {running_loss/print_every:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d2ff8-d5fd-4eb3-83b5-bcdb99f5c2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a figure with 3 rows and 5 columns (to display 15 images total)\n",
    "fig, axs = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for i in range(15):\n",
    "    idx = np.random.choice(range(len(x_test)))\n",
    "    im = x_test[idx]\n",
    "    label = y_test[idx]\n",
    "    # Move the subplot index to row and column indices\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "\n",
    "    # Display the image\n",
    "    axs[row, col].imshow(im[0], cmap='gray')\n",
    "    \n",
    "    # Disable axis for a cleaner view\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        im_tensor = torch.Tensor(im).to(device).unsqueeze(0) # Add batch and channel dimensions\n",
    "        pred = model(im_tensor)\n",
    "        pred = pred.cpu().detach().numpy() \n",
    "        pred = one_hot_decode(pred[0])  # Assuming one_hot_decode() decodes model output to label\n",
    "        pred = num_to_char[pred]        # Map the prediction to character\n",
    "        \n",
    "        # Set the title of each image with the prediction\n",
    "        axs[row, col].set_title(\"pred : \" + str(pred))\n",
    "\n",
    "# Adjust layout so that titles and images don't overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d0323-97a3-4bf4-bb03-948b021e7726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
